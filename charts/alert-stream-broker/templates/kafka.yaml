apiVersion: kafka.strimzi.io/{{ .Values.strimziAPIVersion }}
kind: Kafka
metadata:
  name: {{ .Values.cluster.name }}
spec:
  kafka:
    version: {{ .Values.kafka.version }}
    replicas: {{ .Values.kafka.replicas }}
    listeners:
      - name: internal
        port: 9092
        type: internal
        tls: true
        authentication:
          type: tls
      - name: tls  # Used by the schema registry; it has a fixed name it expects
        port: 9093
        type: internal
        tls: true
        authentication:
          type: tls
      - name: external
        port: 9094
        type: loadbalancer
        tls: true
        authentication:
          type: scram-sha-512
        configuration:
          {{- /*

          This is complicated looking, but that's just because these are all
          optional parameters. They're optional because we don't actually know
          the right IP addresses to use on a fresh deployment.

          The LoadBalancer Service type triggers automatic creation of a cloud
          load balancer, which will get provisioned with some IP address that
          we don't actually choose - it's picked for us. Once that has been
          done, these options make it possible to pin the IP address: we can
          request the actual IP that we already have. This is important because
          it lets us configure a DNS record, associating a hostname with that
          pinned IP address.

          */}}
          bootstrap:

            {{- if .Values.kafka.externalListener.bootstrap.ip }}
            loadBalancerIP: {{ .Values.kafka.externalListener.bootstrap.ip }}
            {{- end }}

          {{- if .Values.kafka.externalListener.brokers }}
          brokers:
            {{- range $idx, $broker := .Values.kafka.externalListener.brokers }}
            - broker: {{ $idx }}
              loadBalancerIP: {{ $broker.ip }}
              advertisedHost: {{ $broker.host }}
            {{- end }}
          {{- end }}

          {{- if .Values.kafka.externalListener.bootstrap.host }}
          brokerCertChainAndKey:
            secretName: {{ .Values.cluster.name }}-external-tls
            certificate: tls.crt
            key: tls.key
          {{- end }}

    authorization:
      type: simple
{{- if .Values.superusers }}
      superUsers:
{{- range .Values.superusers }}
        - {{ . }}
{{- end }}
{{- end }}

    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      log.message.format.version: {{ .Values.kafka.logMessageFormatVersion }}
      inter.broker.protocol.version: {{ .Values.kafka.interBrokerProtocolVersion }}
      ssl.client.auth: required
      {{- range $key, $value := .Values.kafka.config }}
      {{ $key }}: {{ $value }}
      {{- end }}
    storage:
      type: jbod
      volumes:
        # Note that storage is configured per replica. If there are 3 replicas,
        # and 2 volumes in this array, each replica will get 2
        # PersistentVolumeClaims for the configured size, for a total of 6
        # volumes.
      - id: 0
        type: persistent-claim
        size: {{ .Values.kafka.storage.size }}
        class: {{ .Values.kafka.storage.storageClassName }}
        deleteClaim: false

    template:
      pod:
        {{- if .Values.kafka.nodePool.tolerations }}
        tolerations:
          {{- range $tol := .Values.kafka.nodePool.tolerations }}
          - key: {{ $tol.key }}
            operator: "Equal"
            value: {{ $tol.value }}
            effect: {{ $tol.effect }}
          {{- end }}
        {{- end }}

        {{- if .Values.kafka.nodePool.affinities }}
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              {{- range $affinity := .Values.kafka.nodePool.affinities }}
              - weight: 1
                preference:
                  matchExpressions:
                      - key: {{ $affinity.key }}
                        operator: In
                        values: [{{ $affinity.value }}]
              {{- end }}
        {{- end }}

  zookeeper:
    replicas: {{ .Values.zookeeper.replicas }}
    storage:
      # Note that storage is configured per replica. If there are 3 replicas,
      # each will get its own PersistentVolumeClaim for the configured size.
      type: persistent-claim
      size: {{ .Values.zookeeper.storage.size }}
      class: {{ .Values.zookeeper.storage.storageClassName }}
      deleteClaim: false

    template:
      pod:
        {{- if .Values.kafka.nodePool.tolerations }}
        tolerations:
          {{- range $tol := .Values.kafka.nodePool.tolerations }}
          - key: {{ $tol.key }}
            operator: "Equal"
            value: {{ $tol.value }}
            effect: {{ $tol.effect }}
          {{- end }}
        {{- end }}

        {{- if .Values.kafka.nodePool.affinities }}
        affinity:
          nodeAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
              {{- range $affinity := .Values.kafka.nodePool.affinities }}
              - weight: 1
                preference:
                  matchExpressions:
                      - key: {{ $affinity.key }}
                        operator: In
                        values: [{{ $affinity.value }}]
              {{- end }}
        {{- end }}

  entityOperator:
    topicOperator: {}
    userOperator: {}
