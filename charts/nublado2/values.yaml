# Default values for nublado2.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

jupyterhub:
  hub:
    image:
      name: lsstsqre/nublado2
      tag: "1.0.1"
    containerSecurityContext:
      runAsUser: 768
      runAsGroup: 768
      allowPrivilegeEscalation: false
    baseUrl: '/n2'
    # Note: this has to match up with the kubernetes secret created by the vault secret,
    # and since you can't put templating in a values file, I'm just setting the name here,
    # as well as in vault_secret_name, which should match.
    existingSecret: "nublado2-secret"
    extraConfig:
      nublado.py: |
        import nublado2.hub_config
        nublado2.hub_config.HubConfig().configure(c)
    extraVolumes:
      - name: nublado-config
        configMap:
          name: nublado-config
      - name: nublado-gafaelfawr
        secret:
          secretName: nublado-gafaelfawr
    extraVolumeMounts:
      - name: nublado-config
        mountPath: /etc/jupyterhub/nublado_config.yaml
        subPath: nublado_config.yaml
      - name: nublado-gafaelfawr
        mountPath: /etc/keys/signing_key.pem
        subPath: signing-key
    networkPolicy:
      # This is set to disabled but is basically re-implemented by
      # the netpol.yaml in this chart.
      enabled: false

  prePuller:
    continuous:
      enabled: false
    hook:
      enabled: false

  singleuser:
    cmd: "/opt/lsst/software/jupyterlab/provisionator.bash"
    defaultUrl: "/lab"

  auth:
    type: custom
    custom:
      className: nublado2.auth.GafaelfawrAuthenticator
    state:
      enabled: true

  # This is specific to the outdated 0.9.0-n409.hce116620 version of the
  # chart.  When we upgrade to the current version, change this setting
  # to:
  #
  # proxy:
  #   chp:
  #     networkPolicy:
  #       interNamespaceAccessLabels: accept
  proxy:
    service:
      type: ClusterIP
    networkPolicy:
      ingress:
        - ports:
            - port: http
          from:
            - podSelector:
                matchLabels:
                  hub.jupyter.org/network-access-proxy-http: "true"
              namespaceSelector:
                matchLabels: {}

  # Any instantiation of this chart must also set ingress.hosts and add
  # the nginx.ingress.kubernetes.io/auth-signin annotation pointing to the
  # appropriate fully-qualified URLs for the Gafaelfawr /login route.
  ingress:
    enabled: true
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-method: GET
      nginx.ingress.kubernetes.io/auth-response-headers: "X-Auth-Request-Token"
      nginx.ingress.kubernetes.io/auth-url: "http://gafaelfawr-service.gafaelfawr.svc.cluster.local:8080/auth?scope=exec:notebook"
      nginx.ingress.kubernetes.io/configuration-snippet: |
        error_page 403 = "/auth/forbidden?scope=exec:notebook";

config:
  # base_url must be set in each instantiation of this chart to the URL of
  # the primary ingress.  It's used to construct API requests to the
  # authentication service (which should go through the ingress).
  base_url: ""
  signing_key_path: "/etc/keys/signing_key.pem"

  # What uid should the pod be started as?  If it is set, use that uid for
  # starting each pod.  If not set, use the uid provided from gafaelfawr in
  # auth.
  # Sometimes, we start the pod as the provisioning user (uid 769) which has
  # the permission to sudo to do the work of changing to the user.
  pod_uid: 769
  options_form:
    images: []
    images_url: "http://cachemachine.cachemachine/cachemachine/jupyter/available"
    sizes:
      - name: Tiny
        cpu: .5
        ram: 1536M
      - name: Small
        cpu: 1
        ram: 3072M
      - name: Medium
        cpu: 2
        ram: 6144M
      - name: Large
        cpu: 4
        ram: 12288M
  user_resources:
    - apiVersion: v1
      kind: Namespace
      metadata:
        name: "{{ user_namespace }}"
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: lab-environment
        namespace: "{{ user_namespace }}"
      data:
        EXTERNAL_INSTANCE_URL: "{{ base_url }}"
        FIREFLY_ROUTE: /portal/app
        HUB_ROUTE: /n2
        JS9_ROUTE: /js9
        API_ROUTE: /api
        TAP_ROUTE: /api/tap
        SODA_ROUTE: /api/image/soda
        WORKFLOW_ROUTE: /wf
        AUTO_REPO_URLS: https://github.com/lsst-sqre/notebook-demo
        EXTERNAL_GROUPS: "{{ external_groups }}"
        EXTERNAL_UID: "{{ uid }}"
        ACCESS_TOKEN: "{{ token }}"
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: group
        namespace: "{{ user_namespace }}"
      data:
        group: |
          root:x:0:
          bin:x:1:
          daemon:x:2:
          sys:x:3:
          adm:x:4:
          tty:x:5:
          disk:x:6:
          lp:x:7:
          mem:x:8:
          kmem:x:9:
          wheel:x:10:
          cdrom:x:11:
          mail:x:12:
          man:x:15:
          dialout:x:18:
          floppy:x:19:
          games:x:20:
          tape:x:33:
          video:x:39:
          ftp:x:50:
          lock:x:54:
          audio:x:63:
          nobody:x:99:
          users:x:100:
          utmp:x:22:
          utempter:x:35:
          input:x:999:
          systemd-journal:x:190:
          systemd-network:x:192:
          dbus:x:81:
          ssh_keys:x:998:
          lsst_lcl:x:1000:{{ user }}
          tss:x:59:
          cgred:x:997:
          screen:x:84:
          jovyan:x:768:{{ user }}
          provisionator:x:769:
          {{user}}:x:{{uid}}:{% for group in groups %}
          {{ group.name }}:x:{{ group.id }}:{{ user }}{% endfor %}
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: gshadow
        namespace: "{{ user_namespace }}"
      data:
        gshadow: |
          root:!::
          bin:!::
          daemon:!::
          sys:!::
          adm:!::
          tty:!::
          disk:!::
          lp:!::
          mem:!::
          kmem:!::
          wheel:!::
          cdrom:!::
          mail:!::
          man:!::
          dialout:!::
          floppy:!::
          games:!::
          tape:!::
          video:!::
          ftp:!::
          lock:!::
          audio:!::
          nobody:!::
          users:!::
          utmp:!::
          utempter:!::
          input:!::
          systemd-journal:!::
          systemd-network:!::
          dbus:!::
          ssh_keys:!::
          lsst_lcl:!::{{ user }}
          tss:!::
          cgred:!::
          screen:!::
          jovyan:!::{{ user }}
          provisionator:!::
          {{ user }}:!::{% for g in groups %}
          {{ g.name }}:!::{{ user }}{% endfor %}
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: passwd
        namespace: "{{ user_namespace }}"
      data:
        passwd: |
          root:x:0:0:root:/root:/bin/bash
          bin:x:1:1:bin:/bin:/sbin/nologin
          daemon:x:2:2:daemon:/sbin:/sbin/nologin
          adm:x:3:4:adm:/var/adm:/sbin/nologin
          lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
          sync:x:5:0:sync:/sbin:/bin/sync
          shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
          halt:x:7:0:halt:/sbin:/sbin/halt
          mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
          operator:x:11:0:operator:/root:/sbin/nologin
          games:x:12:100:games:/usr/games:/sbin/nologin
          ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
          nobody:x:99:99:Nobody:/:/sbin/nologin
          systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin
          dbus:x:81:81:System message bus:/:/sbin/nologin
          lsst_lcl:x:1000:1000::/home/lsst_lcl:/bin/bash
          tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin
          provisionator:x:769:769:Lab provisioning user:/home/provisionator:/bin/bash
          {{ user }}:x:{{ uid }}:{{ uid }}::/home/{{ user }}:/bin/bash
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: shadow
        namespace: "{{ user_namespace }}"
      data:
        shadow: |
          root:*:18000:0:99999:7:::
          bin:*:18000:0:99999:7:::
          daemon:*:18000:0:99999:7:::
          adm:*:18000:0:99999:7:::
          lp:*:18000:0:99999:7:::
          sync:*:18000:0:99999:7:::
          shutdown:*:18000:0:99999:7:::
          halt:*:18000:0:99999:7:::
          mail:*:18000:0:99999:7:::
          operator:*:18000:0:99999:7:::
          games:*:18000:0:99999:7:::
          ftp:*:18000:0:99999:7:::
          nobody:*:18000:0:99999:7:::
          systemd-network:*:18000:0:99999:7:::
          dbus:*:18000:0:99999:7:::
          lsst_lcl:*:18000:0:99999:7:::
          tss:*:18000:0:99999:7:::
          provisionator:*:18000:0:99999:7:::
          {{user}}:*:18000:0:99999:7:::
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: dask
        namespace: "{{ user_namespace }}"
      data:
        dask_worker.yml: |
          {{ dask_yaml | indent(4) }}
    - apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: "{{ user }}-serviceaccount"
        namespace: "{{ user_namespace }}"
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: Role
      metadata:
        name: "{{ user }}-role"
        namespace: "{{ user_namespace }}"
      rules:
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create", "get", "delete", "list"]
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: "{{ user }}-rolebinding"
        namespace: "{{ user_namespace }}"
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: Role
        name: "{{ user }}-role"
      subjects:
      - kind: ServiceAccount
        name: "{{ user }}-serviceaccount"
        namespace: "{{ user_namespace }}"


# Note: See note above about existingSecret.
vault_secret_name: "nublado2-secret"
vault_secret_path: ""

# Pull secret:
pull_secret: ""

network_policy:
  enabled: true

gafaelfawr_secret_path: ""
